\section{State of the Art}
\subsection{Named Data Networking (NDN)}\label{sec:ndn-sota}
NDN uses two core primitives - \textit{Interest} packets and \textit{Data} packets. In order to request a piece of data from the network, an Interest packet is sent out with the name field set to the name of the required piece of data.

NDN requires three key data structures to operate - a \textit{Forwarding Information Base (FIB)}, a \textit{Pending Interest Table (PIT)} and a \textit{Content Store (CS)}. 

The FIB is used to determine which interface(s) an incoming Interest should be forwarded upstream through. This is similar to FIB used on IP routers. The PIT stores the names of Interests and the interface on which the Interest was received, for Interests which have been forwarded upstream, but not yet had any Data returned. The CS is used to cache Data packets received in response to Interests expressed. The CS allows any NDN node to satisfy an interest if it has the corresponding Data packet, even if it is not the producer itself.


% The operation of an NDN node on receipt of an Interest packet is shown in \reffig{fig:ndn-on-interest}.  

% \begin{figure}
%     \centering
%     \figsize{assets/soa/ndn/incoming-interest.png}{0.3}
%     \caption{Operation performed by an NDN node upon receiving an Interest}
%     \label{fig:ndn-on-interest}
% \end{figure}

On receipt of an Interest, the CS is checked to see if there is a cached copy of the Data corresponding to the name in the Interest. If a copy exists with the appropriate freshness, the Data packet can be sent back over the requesting Face and the Interest packet is satisfied. Thus, NDN provides \textbf{in-network caching}

If there is no cached copy of the Data in the CS, the PIT is then checked. If a PIT entry containing the Interest name exists, this indicates that an equivalent Interest packet has already been seen and forwarded upstream. In this case, the Interest packet is \textbf{not forwarded upstream} a second time. Instead, the requesting face is added to the list of downstream faces in the PIT entry. This list of faces represents the downstream links which are interested in a copy of the Data. This is known as \textbf{Interest aggregation}.

If there is no PIT entry, the FIB is then queried to extract the next hop information for the given Interest. If there is no next hop information, a NACK is typically returned. If an FIB entry is present, a PIT entry for the given Interest is created and the packet is forwarded upstream, using the next hop contained in the FIB entry. 

% The operation of an NDN node on receipt of a Data packet is shown in \reffig{fig:ndn-on-data}.
% \begin{figure}
%     \centering
%     \figsize{assets/soa/ndn/incoming-data.png}{0.3}
%     \caption{NDN operation on receiving Data}
%     \label{fig:ndn-on-data}
% \end{figure}


On receiving a Data packet, the PIT is checked to ensure that the Data packet had actually been requested. If there is no PIT entry, the node never expressed or forwarded an Interest for this piece of data. This means the Data packet is unsolicited and is typically dropped.

Otherwise, the Data packet is sent over all of the requesting faces contained in the PIT entry, the PIT entry is removed and the Data is added to the CS. Thus, a single Data packet published by a producer can be sent to multiple consumers, meaning NDN supports \textbf{native multicast}.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NDN Routing and Forwarding
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Routing and Forwarding}\label{sec:routing}
% IP routers use \textit{stateful routing} and a \textit{stateless forwarding plane}. This means that routers maintain some state on where to forward packets given their destination IP addresses (stateful routing). However, when it comes to actually forwarding packets, the packets are sent over the chosen route and forgotten about (stateless forwarding). NDN on the other hand, uses both stateful forwarding and routing \cite{stateful-forwarding} in order to accomplish routing packets by name and not address, as seen by the usage of a PIT. NDN routing is done based on the name fields of Interest and Data packets and will select the route which has the \textit{longest prefix} in common with the name in the packet. 


% However, there are three key benefits offered by NDN's stateful forwarding plane - \textit{multipath forwarding}, \textit{native multicast} and \textit{adaptive forwarding}.

% \subsubsection*{Multipath Forwarding} \label{sec:multipath-forwarding}
% One of the challenges of routing IP packets using a stateless forwarding plane is ensuring that there are no forwarding loops. Otherwise a single packet could loop endlessly throughout the network. The typical approach to solving this problem is to use the \textit{Spanning Tree Protocol (STP)} \cite{spanning-tree-protocol} to build a loop free topology. This results in a single optimal path between any two nodes in a network and disables all other paths.

% However, as NDN uses a stateful forwarding plane, looping Interest packets can be detected and stopped. As discussed in \refsec{sec:ndn-packet-structure}, Interest's contain a \textit{Nonce} field, allowing Interests to be uniquely identified. If an NDN router sees an Interest which is identical to an Interest in the PIT, the Interest is ignored as a loop has been detected. That is, the usage of a PIT prevents looping. Similarly, as Data packets take the reverse path of the Interest packets, they also cannot loop. 

% This means NDN can natively support multipath forwarding. This is done by allowing multiple next hops for a given entry in the FIB. This provides flexibility in the routing protocols which can be used with NDN and offers several benefits such as load balancing across entries in the FIB. Thus, to take advantage of the native multipath forwarding capabilities, an NDN specific routing protocol was developed (see \refsec{sec:NLSR})

% \subsubsection*{Native Multicast}
% As discussed in \refsec{sec:ndn-basic-operation}, when a router receives an Interest which matches an entry in the PIT, it does not forward the second Interest upstream. Instead it adds the Face over which the incoming Interest was received to the PIT entry. Once the data for the Interest reaches the router, it forwards the Data packet to \textbf{all} of the faces listed in the PIT entry. Thus, NDN natively supports multicast as a producer may produce a single Data packet and have it reach many consumers. 

% \subsubsection*{Adaptive Forwarding}
% As NDN's forwarding plane is stateful, routers can dynamically adapt where they forward packets as the needs arise. Routers can track performance metrics such as round-trip-times of upstream connections and can use this information to detect temporary link failures, or poorly performing links and route around them.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NDN Benefits in MOG
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Benefits in a MOG Context}\label{sec:sota:mog-ndn-benefits}
% As outlined in \refsec{sec:mogs}, MOGs can be built using a variety of architectures, can have a variety of different data types and require extremely high-performance networking solutions. As such, MOGs are an excellent test of the performance of new networking technologies and architectures such as NDN. The three major benefits offered by NDN in a MOG context are \textit{Interest aggregation}, \textit{native multicast} and \textit{in-network caching}.

% \begin{figure}[H]
%     \centering
%     \figsize{assets/soa/ndn/agg-multicast.png}{0.9}
%     \caption{Interest aggregation (b), native multicast (c) and in-network caching (d)}
%     \label{fig:agg-multicast}
% \end{figure}


% \subsubsection*{Interest Aggregation}
% As discussed in \refsec{sec:ndn-basic-operation}, the use of a PIT allows NDN routers to aggregate Interests and has the potential to drastically reduce network traffic in the process. In a P2P MOG architecture, every player is typically interested in the data being produced by every other player. This means there are $n^2$ logical connections required, where $n$ is the total number of game players, assuming the typical architecture in which every player is responsible for publishing their own updates. In a traditional UDP/IP based implementation, all $n^2$ of these logical connections are required as actual connections via a UDP tunnels, or something similar.

% However, in an NDN based implementation, considering \textit{"connections"} no longer makes sense. Considering the fact that $n-1$ players are likely to be expressing Interests for a given player's Data, Interest aggregation plays a major role in reducing network traffic, as only one instance of the same Interest will be forwarded upstream by each intermediate router. 

% As the Interests from separate consumers are forwarded closer and closer to the producer, it becomes more and more likely that they will reach a common intermediate router and be aggregated, although this depends on the topology. The earlier this occurs in the topology the better, as it counteracts the issue stemming from the $n^2$ logical connections required due to the P2P architecture.

% Interest aggregation would also benefit the Client/Server architecture in much the same way, as Interests would be aggregated on route to the server, just as they would be in a P2P architecture while on route to a producer.

% Consider the case in which node A expresses an Interest for node D's status (\reffig{fig:agg-multicast} (a)). This Interest reaches the router, who creates a PIT entry and forwards the Interest to node D. If node B then expresses an Interest for node D's status, the Interest will be aggregated at the intermediate router, as a PIT entry exists for this Data. This means the Interest will not be forwarded upstream to node D a second time, reducing the network traffic seen over the link between the router and node D (\reffig{fig:agg-multicast} (b)).



% \subsubsection*{Native Multicast}
% The core concept behind multicast is producing a piece of data once and having it reach multiple consumers. As previously discussed, NDN provides this functionality natively as a direct result of NDN's stateful forwarding plane. Considering MOG networking from a higher level, the architecture is essentially one of \textit{publish-subscribe (pub-sub)}, in which game players (publishers) must publish data to all other players in the game (subscribers). Native multicast is a direct benefit over traditional UDP/IP which requires the same piece of data to be sent to every client, requiring $\mathcal{O}(n)$ sends. 

% As seen in \reffig{fig:agg-multicast} \textit{(c)}, once node D has the data to satisfy the Interest expressed by node A, node D will send \textbf{one} Data packet back to the router. However, as there are \textbf{two} downstream faces in the router's PIT entry for this Data packet, the router will send this Data packet to both nodes A and B. This means node D's Data packet will be multicasted to both nodes A and B. 

% \subsubsection*{In-Network Caching}
% As NDN routers use opportunistic caching via the CS, frequently requested or recently produced Data packets can be cached and served by intermediate routers. This can reduce the round-trip-times of fetching updates from the network and in turn, the overall latency of the MOG. 

% Although static content (see the taxonomy of MOG data in \refsec{sec:taxonomy}) would likely see relatively high cache rates, the frequency at which static content would be fetched would likely be as low as once per game, meaning the overall network impact would likely be negligible in comparison to the more frequently fetched data which may not be cacheable. 

% However, considering the outstanding Interest architecture, in which all consumers keep an outstanding Interest and wait for producers to produce the next Data packet (see \refsec{sec:des:sync-protocol}), the effects of caching come into play in the case where a consumer falls slightly behind in fetching remote updates. 

% For example, if a publisher produces a Data packet every 100ms, it is likely that, in the steady-state, Interests from most of the consumers would be aggregated while the consumers wait on the next packet to be produced. Once this packet is produced, the Data will be multicasted back to all consumers who requested it as previously described. 

% However, consider the case where a consumer falls slightly behind the other consumers and expresses an Interest for a piece of Data which has already been produced. Without caching, this would require a full round trip all the way to the data producer, putting an extra strain on the network. 

% Also, while the lagging consumer is fetching the old Data packet, the other consumers will be requesting the \textbf{next} Data packet. This means the lagging consumer will continue to remain behind and continue to essentially \textbf{double} the rate of Interests seen by the producer, and significantly increase the amount of network traffic required to synchronize a sequenced piece of Data.  

% However, if caching is used, this Data can be returned from the CS of the first intermediate router who previously forwarded this Interest on behalf of another consumer. Thus, the consumer can potentially receive this somewhat stale Data much quicker and will hopefully catch up with the other consumers. If the consumer continues to lag behind, they will simply continue to obtain cached copies from intermediate routers, limiting the impact on the overall network.

% An example of this scenario is seen in \reffig{fig:agg-multicast} (d), where node C requests the status of node D. However, as this data has already been fetched by nodes A and B, the Data packet will be available in the CS of the router. This will allow node C to receive the Data packet much faster, and reduce the strain on link between the router and node D.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Distributed Dataset Sync
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Dataset Synchronization (DS) in NDN}\label{sec:dataset-sync}
A common requirement in distributed, P2P environments is for nodes to read and write to a shared dataset. In order to provide all participants with a common view of the dataset, a \textit{dataset synchronization protocol (DSP)} is required. The importance of DSPs is amplified in an NDN context as most applications are developed with a distributed P2P architecture in mind. This is done to enable high scalability through the exploitation of the features offered by NDN such as in-network caching and native multicast. As such, a lot of research into the area of DS in NDN has been conducted and one of the goals of the research is to abstract away the need for NDN application developers to consider DS.

Traditionally, IP based solutions for DS take one of two approaches - centralized or decentralized. 

% Centralized approaches require a centralized node which becomes the authoritative source on the state of the dataset. All nodes communicate directly with this node and updates to the dataset are sent through this node. This simplifies the problem considerably at the cost of creating a bottleneck in the system.

Alternatively, a decentralized approach can be taken in which all nodes communicate with one and other. In an IP based solution, this requires each node to maintain $n-1$ connections to every other node, for example using a TCP socket. This approach mitigates the problem of having a bottleneck in the system, resulting in a more scalable solution, at the cost of requiring a considerably more complex protocol in order to maintain a consistent view of the dataset amongst all nodes.

Decentralized approaches are typically more scalable than centralized approaches, though the scalability of the decentralized approach is limited by the connection oriented abstraction of IP, as the number of connections required scales quadratically with the number of nodes. The data oriented abstraction of NDN overcomes this issue as nodes are no longer concerned with \textit{who} they communicate with and are instead concerned with producing and consuming named pieces of data, which can be fetched from and published to the network. The decentralized approach also benefits from the features offered by NDN such as interest aggregation, native multicast and in-network caching.

NDN can achieve distributed DS by synchronizing the namespace of the shared dataset among a group of distributed nodes \cite{sync-survey}. Several protocols have been developed to achieve this including CCNx Sync 1.0 \cite{ccnx-sync}, iSync \cite{isync}, ChronoSync \cite{chronosync}, RoundSync \cite{roundsync} and PSync \cite{psync}. Although many of these existing DSPs are well developed, they are not suitable for use in a MOG environment as they only inform nodes of updates to the dataset, and require a second Interest / Data exchange to fetch the updates. Due to the low latency required for MOGs, a protocol which retrieves updates in a single Interest / Data exchange is required.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MOGs
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Multiplayer Online Games (MOGs)}
On a fundamental level there are only two architectures to choose from, \textit{Client/Server (C/S)} or \textit{Peer-to-Peer (P2P)}. However, there is a huge amount of variation within each of those architectures and even combinations of the two architectures such as \textit{MultiServer (MS)}, which uses a small number of centralized servers to somewhat distribute the load, and \textit{Hybrid} which uses both C/S and P2P elements. The trade-offs between C/S and P2P architectures in a MOG context are very similar to those found elsewhere in computer science. C/S architectures are simpler and more robust to cheating, but suffer from scalability issues and the opposite is true for P2P architectures.

MOGs typically follow a \textit{primary copy} replication approach. For each game object (e.g. players and NPCs), there exists an authoritative \textit{primary} copy, and this exists on one node only. All other copies are \textit{secondary copies}, and are merely replicas of the primary copy. All updates to game objects are performed on \textbf{primary copies only}. The results of these update operations are then sent to all other players, who update their secondary copies accordingly \cite{p2p-mog-survey}.

In video games, the rate at which the local game world is updated and redrawn at is known as the \textit{frame rate} and anything below 30 frames-per-second results in a poor user experience. Using the Internet as it stands today, consistently receiving remote updates at a rate of even 30Hz would be extremely challenging and unreliable due to packet loss, limited bandwidth, congestion and propagation times alone. The requirement for extremely frequent updates, coupled with the amount of remote game objects that need updating, means that moving remote game objects based on received updates alone is simply not feasible, and attempting to do so leads to very jittery movement. Dead reckoning (DR) is a commonly employed solution to this problem in which remote game objects are locally updated at a frequency higher than the rate of updates received for those game objects. As described by Walsh, Ward and McLoone \cite{dead-reckoning}, \textit{"DR is a short term linear extrapolation algorithm which utilises information relating to the dynamics of an entity’s state and motion, such as position and velocity, to model and predict future behaviour"}. By including an entity's velocity as well as their new position in remote update packets, an extrapolated trajectory can be built for the game object, which defines their future position as a function of time. The local client can then move the remote game object along this trajectory in between actual remote updates, providing the appearance of smooth motion. Another interesting component of DR is that it can be used to dynamically control the rate at which updates are published. As all parties use the same extrapolation and convergence algorithms, the holder of the primary copy can also maintain a replica copy, which represents the extrapolated position as viewed by remote players. 
This mechanism can be used to dynamically control the rate at which updates are published depending on the motion characteristics of the game object. For example, if the game object is stationary, the extrapolated position over time will remain constant as the velocity vector is also zero. Thus, until the game object begins to move, there is no need to publish further updates. This can also apply to game objects moving on a constant trajectory, for example, a player moving due east in the game world.

Depending on the design of the MOG, players may only see a subsection of the game world at a given time. For example, in a top-down game or side scroller, the camera remains centred on the player's avatar and the player's viewport is a subregion of the entire game world. Similarly, in more complex 3D games, the player's view of the game world may be obstructed by objects such as rocks or trees, or the player may be inside of a building. The game world may also be divided into geographical regions such that a player's view of the game world is strictly limited to the geographical region they are currently in. In all cases, there is an opportunity to drastically reduce the amount of game objects that must be synchronized to present a consistent view of the game world to the player. This concept is defined in the literature as \textit{interest management (IM)}. The most prevalent form of IM is \textit{spatial IM}, in which only game objects that can be seen by the player are synchronized.







% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Architectures 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Architectures}
% One of the first decisions to make when designing the backend of a MOG is which architecture to use. On a fundamental level there are only two architectures to choose from, \textit{Client/Server (C/S)} or \textit{Peer-to-Peer (P2P)}. However, there is a huge amount of variation within each of those architectures and even combinations of the two architectures such as \textit{MultiServer (MS)}, which uses a small number of centralized servers to somewhat distribute the load, and \textit{Hybrid} which uses both C/S and P2P elements. As one would expect, there are substantial benefits and drawbacks to all of these architectures and the choice of which to use will play a major role on the scalability, consistency, security, ease of development and cost of running of the MOG. 

% MOGs typically follow a \textit{primary copy} replication approach. For each game object (e.g. players and NPCs), there exists an authoritative \textit{primary} copy, and this exists on one node only. All other copies are \textit{secondary copies}, and are merely replicas of the primary copy. All updates to game objects are performed on \textbf{primary copies only}. The results of these update operations are then sent to all other players, who update their secondary copies accordingly \cite{p2p-mog-survey}.

% \subsubsection*{Client/Server (C/S)}
% C/S is the most common form of MOG architecture today. In the simplest form, C/S consists of a single server which all game players communicate with. The server is the single authoritative source of truth for the game state and holds \textbf{all} primary copies. All updates to the game world and game objects occur on the server and these updates are then pushed to all connected players (clients) by the server.

% The benefits and limitations of a C/S architecture in a MOG context compared to a distributed alternative are very similar to those found elsewhere in computer science. 

% The main benefits are the reduced complexity associated with performing all updates in one place and the added difficulty for players to cheat, since the server can determine whether updates are valid prior to performing them. C/S architectures are an ideal choice for games with a small number of players, or which do not require extremely high-performance networking solutions such as \textit{real time strategy RTS} games. 

% The main limitation associated with the C/S architecture is scalability. Modern MOGs require support for hundreds or even thousands of players in a particular game world, and a single server becomes a severe bottleneck at this scale, regardless of the hardware used. Another potential issue is fault tolerance. Server failures do occur, and the standard C/S architecture provides no fault tolerance whatsoever, meaning the game is entirely unplayable in the event of a server failure.

% However, substantial research and engineering has allowed C/S based architectures to meet the demands of modern MOGs and it is still the most commonly used architecture today \cite{p2p-mog-survey}. The main mechanism for achieving the scalability required is to distribute players among several servers. Clients can be distributed among servers based on their physical locations in the real world or their virtual locations in the virtual world \cite{dist-mog-loadsharing}.

% Distributing players based on their virtual locations is the ideal choice, as it does not entirely segregate players. However, it is more challenging in that a hand-off mechanism is likely required as players cross server boundaries. It can also face scalability issues as players tend to congregate at certain places in the virtual world, such as towns or cities \textit{(flocking behaviour)}, meaning a single server may still struggle due to the density of players in a particular region. 

% \subsubsection*{Peer-to-Peer (P2P)}
% P2P architectures contain no centralized server. Instead, each peer in the network becomes the authoritative source of certain game objects and holds their primary copies. As before, updates are performed only on primary copies. Thus, peers become responsible for accepting update requests, performing updates and disseminating updates to all other peers in the network.

% A common method for building MOGs using a P2P architecture is to create an overlay network, backed by a \textit{distributed hash table} \cite{p2p-mog-dht}. These typically use Pastry to build a \textit{"decentralized, self-organizing and fault-tolerant overlay network, capable of routing messages to other peers in $\mathcal{O}(\log{}n)$ forwarding steps"} \cite{pastry} and Scribe \cite{scribe} which provides an application-level multicast infrastructure using the overlay network built with Pastry.

% In principle, P2P architectures have the highest potential of all architectures for scalability as every peer that joins the game adds new resources to the system. All of the work is distributed amongst the players in the game, mitigating the requirement for expensive, high-performance, centralized servers and providing excellent fault tolerance. 

% However, building MOGs on a P2P architecture is considerably more challenging than in the C/S architecture. The main issue is that updates to game objects are performed across multiple different nodes at different times. This requires much more complex protocols to ensure a consistent view of the game world is provided to all connected players. Finally, as players are responsible for accepting, rejecting and performing updates on primary copies, P2P based architectures are much more vulnerable to cheating. 

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Dead Reckoning 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Dead Reckoning}\label{sec:sota:dead-reckoning}
% In video games, the rate at which the local game world is updated and redrawn at is known as the \textit{frame rate}. The frame rate of a video game is measured in \textit{frames per second (fps)}. Most modern video games aim to run at a minimum frame rate of 30 fps, while targeting higher frame rates such as 60 or even 100 fps. In the case of a 30 fps frame rate, this would require an update to be available for \textbf{all} remote game objects every 33.33 milliseconds (ms). Using the Internet as it stands today, consistently receiving remote updates at a rate of even 30Hz would be extremely challenging and unreliable due to packet loss, limited bandwidth, congestion and propagation times alone. The requirement for extremely frequent updates, coupled with the amount of remote game objects that need updating, means that moving remote game objects based on received updates alone is simply not feasible, and attempting to do so leads to very jittery player movement.

% Dead reckoning (DR) is a commonly employed solution to this problem in which remote game objects are locally updated at a frequency higher than the rate of updates received for those game objects. As described by Walsh, Ward and McLoone \cite{dead-reckoning}, \textit{"DR is a short term linear extrapolation algorithm which utilises information relating to the dynamics of an entity’s state and motion, such as position and velocity, to model and predict future behaviour"}.

% By including an entity's velocity as well as their new position in remote update packets, an extrapolated trajectory can be built for the game object, which defines their future position as a function of time. The local client can then move the remote game object along this trajectory in between actual remote updates, providing the appearance of smooth motion.   

% \subsubsection{DR Convergence Algorithms}

% Upon receipt of a remote update packet, it is likely that the extrapolated position does not exactly match the updated position. As such, a DR \textit{convergence algorithm} is required. The most basic form of this algorithm is to directly overwrite the game object's extrapolated position with the new position. However, this can result in remote game objects appearing to suddenly jump to the new updated position, instead of smoothly moving towards it. 

% The main challenge with DR convergence algorithms is that the difference between the previously extrapolated position and the actual updated position must be reconciled, \textbf{while continuing to extrapolate} the game object towards a future position.

% An example DR convergence algorithm designed by Delaney et al. \cite{dead-reckoning-convergence} is given below:

% \begin{itemize}
%     \item Let the current extrapolated position of a remote player be $p_{ex}$
%     \item A remote update is received containing $p_{new}$ and $v_{new}$ representing the player's new position and velocity respectively
%     \item The extrapolated position for remote player $p'_{ex}$ is built using $p_{new}$ and $v_{new}$ which represents the best approximation for where the player will be in $n$ time steps,
%     \item A trajectory is built such that the player will reach $p'_{ex}$ from $p_{ex}$ in $n$ time steps, and the player is moved along this trajectory.  
% \end{itemize}

% This algorithm allows the extrapolated position to be reconciled with the updated position, while still extrapolating the player towards an approximated future position.


% \subsubsection{DR Update Throttling}
% Another interesting component of DR is that it can be used to dynamically control the rate at which updates are published. As all parties use the same extrapolation and convergence algorithms, the holder of the primary copy can also maintain a replica copy, which represents the extrapolated position as viewed by remote players. 

% The holder of the primary copy can then use a configurable \textit{threshold value} to determine when an update is required. In the simplest form, this is done by periodically calculating the Euclidean distance between the extrapolated position and the actual primary copy position and publishing an update once this distance exceeds the threshold value. 

% This mechanism can be used to dynamically control the rate at which updates are published depending on the motion characteristics of the game object. For example, if the game object is stationary, the extrapolated position over time will remain constant as the velocity vector is also zero. Thus, until the game object begins to move, there is no need to publish further updates. This can also apply to game objects moving on a constant trajectory, for example, a player moving due east in the game world. 

% An interesting component of this method is choosing the threshold value. This value is chosen to minimize network traffic without negatively impacting the apparent consistency of the game world. This choice is similar to choosing the amount of compression to apply to an audio or video stream. Research conducted by Kenny, McLoone, Ward and Delaney examined the impacts of different threshold values by performing experiments with real people, in an attempt to determine an optimal value \cite{dead-reckonining-threshold-learning}. 



% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Area of Interest MGMT 
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Interest Management}\label{sec:interest-management}
% Depending on the design of the MOG, players may only see a subsection of the game world at a given time. For example, in a top-down game or side scroller, the camera remains centred on the player's avatar and the player's viewport is a subregion of the entire game world. Similarly, in more complex 3D games, the player's view of the game world may be obstructed by objects such as rocks or trees, or the player may be inside of a building. The game world may also be divided into geographical regions such that a player's view of the game world is strictly limited to the geographical region they are currently in.

% In all cases, there is an opportunity to drastically reduce the amount of game objects that must be synchronized to present a consistent view of the game world to the player. This concept is defined in the literature as \textit{interest management (IM)}. The most prevalent form of IM is \textit{spatial IM}, in which only game objects that can be seen by the player are synchronized.

% However, a somewhat assumed form of IM in MOGs is \textit{temporal} in nature. MOGs are essentially realtime applications, and players typically do not need to know about data that was generated earlier, as the game world has moved on from that point. 

% There are also opportunities to employ IM by exploiting certain features of the actual game. For example, in a team-based shooting game, the position and status of allies could likely be synchronized less aggressively than that of enemies, as the player's focus is more likely on the enemies they are fighting.

% An important aspect of IM is that there is a computational cost associated with determining what subset of game objects a given player is interested in. Thus, the benefits gained from employing IM must be carefully weighted against the associated computational overhead \cite{im-thesis}. 
% In this regard, IM mechanisms which push the computation to the actual players are favoured over those which must be performed server-side. Similarly, trading off the computational overhead for memory overhead, through pre-computation ahead of time, can also be beneficial, provided sufficient memory is available.

% The simplest form of IM occurs in the case of a top-down style game, where a player's viewport is a cropped view of the entire game world. Game objects outside of the player's viewport can be disregarded as they cannot be seen by the player. However, dynamic game objects  cannot be disregarded entirely, as their movement may cause them to enter the player's viewport. Instead, the rate at which updates are published to the player for that game object can be slowed, and the contents of the updates can be reduced to only contain the position and velocity of the game object.

% An example of a more complex IM mechanism is \textit{tile based IM}. Tile based IM divides the entire game world into tiles, such that the physical position of all players and game objects will always be on a tile. If an obstacle blocks a portion of a players view of the world, the player should not be interested in any of the game objects behind that obstacle. The simple distance-based form of IM does not handle this case and results in players being interested in more game objects than necessary. Tile based IM solves this problem by taking the actual game world into account \cite{pub-sub-mog}.

% \begin{figure}
%     \centering
%     \figsize{assets/soa/mog/tile-im.png}{0.4}
%     \caption{Tile interest map in a 3D game world}
%     \label{fig:tile-im}
% \end{figure}

%  A \textit{tile interest map} is built for every tile in the game world, which takes all obstacles into account. This can be a relatively expensive process and is typically pre-computed and stored in memory providing fast lookup times. An example of a tile interest map is shown in \reffig{fig:tile-im} in which the player (blue) is not interested in any of game objects on the red tiles as the view of those tiles is obstructed by the obstacle (grey).   



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Closely related projects
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Closely Related Projects}
Projects which focus on researching, designing and building MOGs using NDN as the communication mechanism are very relevant to the project. However, as NDN is still a relatively new technology in an early prototyping stage, only three projects were found in this area.

Egal Car \cite{egal-car} was the first investigation into building a MOG using NDN. Egal Car used an existing single player, Unity based, car racing game and focused on writing a P2P networking module for the game, allowing it to be played as a multiplayer game. The key limitation of Egal Car is that assets were not allowed to interact with one and other. Thus, the problem was simplified to one of DS, in which there is only one producer of content. Egal Car was also created in 2012 and used a framework which is no longer a part of the NDN platform. Finally, Egal Car was a proof of concept prototype, and there was no testing performed and there is no source code publicly available. 

Matryoshka \cite{ndn-multiplayer-game} is another P2P MOG which runs over NDN. The core focus of Matryoshka was to come up with a way to partition the game world such that players would only be interested in other game objects in their partition. This was done by recursively partitioning the game world into 8 octants. In the implementation outlined, the partitioning was two layers deep, although this could be deeper for larger game worlds. The partition to which a game object belongs to is thus defined by two indices, representing the octant they are in at each of the two layers. Although an implementation is discussed, there is no source code available. There paper also lacks any results or evaluation section, indicating the architecture has not been tested.   

NDNGame \cite{ndn-game} describes the use of a hybrid architecture in which a conventional C/S approach using UDP over IP is used for the actual gameplay related networking, and NDN is used for the dissemination of the \textbf{game files}. The logic behind this approach is that the size of the initial files required to play the game are far larger than the packets which are sent when playing the game. The use of the conventional C/S architecture using UDP/IP is chosen due to the importance of network latency when playing the game. The paper's suggestion that using NDN in a MOG scenario is not feasible does not appear to be rooted in any actual testing or empirical evidence and thus, the main finding of the paper is only that NDN would be an ideal candidate for static game file dissemination.  

